{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2c26845d",
      "metadata": {
        "id": "2c26845d"
      },
      "source": [
        "# Langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n",
        "!pip install langchain\n",
        "!pip install google-search-results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTekB4DngWLQ",
        "outputId": "8202cc4e-6a85-411c-8ebe-39a3aeba9391"
      },
      "id": "bTekB4DngWLQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.6.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 openai-1.12.0\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.7-py3-none-any.whl (815 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m815.9/815.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.20 (from langchain)\n",
            "  Downloading langchain_community-0.0.20-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.22 (from langchain)\n",
            "  Downloading langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (3.7.1)\n",
            "Collecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.2.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, typing-inspect, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-community, langchain\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.7 langchain-community-0.0.20 langchain-core-0.1.23 langsmith-0.0.87 marshmallow-3.20.2 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.2.2)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32003 sha256=95fb90b5919a9e0dd4ba51725514227e811b6e1feeb0d74ebfbaddbf757d5b2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/b2/c3/03302d12bb44a2cdff3c9371f31b72c0c4e84b8d2285eeac53\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f31c4cc6",
      "metadata": {
        "id": "f31c4cc6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ed0dc6a",
      "metadata": {
        "id": "9ed0dc6a"
      },
      "source": [
        "## LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa352d5f",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa352d5f",
        "outputId": "1b23ba84-7b7a-4b18-bbaf-c06645163883"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Royal Masala Bistro\"\n"
          ]
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0.9)\n",
        "name = llm.invoke(\"I want to open a restaurant for Indian food. Suggest a fancy name for this.\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm.invoke(\"I want to open a restaurant for Italian food. Suggest a fancy name for this.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "vkHviYYRDwKz",
        "outputId": "93d92c89-64e5-4327-90be-ef387a39071d"
      },
      "id": "vkHviYYRDwKz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n\"La Bella Trattoria\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0782a2dd",
      "metadata": {
        "id": "0782a2dd"
      },
      "source": [
        "## Prompt Templates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a306b9d",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a306b9d",
        "outputId": "684bca75-94e7-4f26-a889-e2372419a765"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to open a restaurant for Italian food. Suggest a fancy name for this.\n",
            "\n",
            "\n",
            "\"La Dolce Vita Ristorante\"\n"
          ]
        }
      ],
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
        ")\n",
        "p = prompt_template_name.format(cuisine=\"Italian\")\n",
        "print(p)\n",
        "\n",
        "print(llm.invoke(p))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af406b92",
      "metadata": {
        "id": "af406b92"
      },
      "source": [
        "## Chains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba65c213",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba65c213",
        "outputId": "ba9c6b29-dbf0-4f0d-ba30-b936c55bf813"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cuisine': 'Mexican',\n",
              " 'text': '\\n\\n\"El Sabor Divino\" (translates to \"The Divine Flavor\")'}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from langchain.chains import LLMChain\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "chain.invoke(\"Mexican\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e5ccee75",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5ccee75",
        "outputId": "f3ca28a2-43d7-412b-bab2-cd75e0744a3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mI want to open a restaurant for Mexican food. Suggest a fancy name for this.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cuisine': 'Mexican', 'text': '\\n\\n\"Cantina del Sol\" '}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, verbose=True)\n",
        "chain.invoke(\"Mexican\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21098937",
      "metadata": {
        "id": "21098937"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0.6)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
        ")\n",
        "\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name)\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"\"\"Suggest some menu items for {restaurant_name}\"\"\"\n",
        ")\n",
        "\n",
        "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87a98d9f",
      "metadata": {
        "id": "87a98d9f"
      },
      "source": [
        "#### Simple Sequential Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9fd9a79",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9fd9a79",
        "outputId": "6be924ae-d51c-4306-bf55-593cbe552a79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'Indian', 'output': '\\n\\n1. Chicken Tikka Masala\\n2. Vegetable Samosas\\n3. Lamb Vindaloo\\n4. Palak Paneer\\n5. Tandoori Chicken\\n6. Chana Masala\\n7. Butter Chicken\\n8. Vegetable Biryani\\n9. Garlic Naan\\n10. Mango Lassi (drink)\\n11. Aloo Gobi (cauliflower and potato curry)\\n12. Dal Makhani (creamy lentil dish)\\n13. Tandoori Shrimp\\n14. Malai Kofta (vegetable and cheese balls in creamy sauce)\\n15. Mango Kulfi (Indian ice cream)\\n16. Chicken Korma (mild and creamy chicken curry)\\n17. Aloo Paratha (potato-stuffed flatbread)\\n18. Saag Paneer (spinach and cheese curry)\\n19. Gulab Jamun (fried milk balls in syrup)\\n20. Mango Chutney (sweet and tangy condiment) '}\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import SimpleSequentialChain\n",
        "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain])\n",
        "\n",
        "content = chain.invoke(\"Indian\")\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0386d05c",
      "metadata": {
        "id": "0386d05c"
      },
      "source": [
        "#### Sequential Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "49dc0fae",
      "metadata": {
        "id": "49dc0fae"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_name = PromptTemplate(\n",
        "    input_variables =['cuisine'],\n",
        "    template = \"I want to open a restaurant for {cuisine} food. Suggest a fancy name for this.\"\n",
        ")\n",
        "\n",
        "name_chain =LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dea8402",
      "metadata": {
        "id": "9dea8402"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0.7)\n",
        "\n",
        "prompt_template_items = PromptTemplate(\n",
        "    input_variables = ['restaurant_name'],\n",
        "    template=\"Suggest some menu items for {restaurant_name}.\"\n",
        ")\n",
        "\n",
        "food_items_chain =LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ec1be10",
      "metadata": {
        "id": "1ec1be10"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import SequentialChain\n",
        "\n",
        "chain = SequentialChain(\n",
        "    chains = [name_chain, food_items_chain],\n",
        "    input_variables = ['cuisine'],\n",
        "    output_variables = ['restaurant_name', \"menu_items\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4653c540",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4653c540",
        "outputId": "539abf2c-0344-4275-b482-32d84519ea3a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cuisine': 'Indian',\n",
              " 'restaurant_name': '\\n\\n\"Maharaja\\'s Palace: A Taste of India\"',\n",
              " 'menu_items': '\\n\\n1. Tandoori Chicken: Marinated chicken cooked in a clay oven\\n2. Vegetable Biryani: Aromatic rice cooked with mixed vegetables and spices\\n3. Butter Chicken: Creamy tomato-based curry with tender chicken pieces\\n4. Saag Paneer: Spinach and cheese curry\\n5. Samosas: Crispy pastry filled with spiced potatoes and peas\\n6. Naan Bread: Traditional Indian flatbread\\n7. Lamb Vindaloo: Spicy curry with tender lamb pieces\\n8. Aloo Gobi: Cauliflower and potato curry\\n9. Mango Lassi: Refreshing yogurt-based drink with mango flavor\\n10. Gulab Jamun: Deep-fried milk dumplings in sugar syrup for dessert.'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "chain.invoke({\"cuisine\": \"Indian\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4069a75e",
      "metadata": {
        "id": "4069a75e"
      },
      "source": [
        "## Agents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e6ee719",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e6ee719",
        "outputId": "a6551636-1fa4-4de7-e970-ff912bd3f569"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.10/dist-packages (2.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from google-search-results) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->google-search-results) (2024.2.2)\n"
          ]
        }
      ],
      "source": [
        "os.environ['SERPAPI_API_KEY'] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "471b2c6b",
      "metadata": {
        "id": "471b2c6b"
      },
      "source": [
        "#### serpapi tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fec4212d",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fec4212d",
        "outputId": "1aafc979-a722-432c-e201-d93df86a511f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should search for the latest GDP data for India.\n",
            "Action: Search\n",
            "Action Input: \"GDP India 2023\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Economy of India', 'source': 'Wikipedia'}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This is a reliable source, but I should double check with another source.\n",
            "Action: Search\n",
            "Action Input: \"India GDP 2023\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m{'type': 'organic_result', 'title': 'Economy of India', 'source': 'Wikipedia'}\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m The results are consistent, but I should also check the official government website.\n",
            "Action: Search\n",
            "Action Input: \"India GDP 2023 official government website\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m['GDP at Current Prices in H1 2023-24 is estimated at ₹142.33 lakh crore as against ₹131.09 lakh crore during the corresponding period of ...', '2024 Projected Real GDP (% Change) : 6.5* ; Country Population: 1,441.720 million ; Date of Membership: December 27, 1945 ; Article IV/Country Report: December 18, ...', \"Economic Survey · Preface · State of the Economy 2022-23: Recovery Complete · India's Medium-term Growth Outlook: With Optimism and Hope · Fiscal Developments: ...\", 'India to witness GDP growth of 6.0 per cent to 6.8 per cent in 2023-24, depending on the trajectory of economic and political developments ...', \"India's real GDP expanded by 7.2 per cent in FY23, the highest among major economies. The latest estimate of real GDP turned out to be higher than the second ...\", 'GDP, current prices. Billions of U.S. dollars. 4.11. thousand. Created with ... Government revenue, percent of GDP. % of GDP. 19.39. Created with Highcharts 6.1.4.', 'Come March, the nominal GDP of India will be around US$ 3.5 trillion. In real terms, the economy is expected to grow at 7 per cent for the year ...', \"In FY22/23, India's real GDP expanded at an estimated 6.9 percent. Growth was underpinned by robust domestic demand, strong investment activity ...\", 'Press Note on Quarterly Estimates of GDP for the quarter July-September (Q2) 2023-24 PDF icon ( 210.29 KB ). 30-11-2023.', 'Home|G20 India 2023 · Portal for Public Grievances | External link that open in new Window · evisitors · egazette · GOI Web Directory · Election Commission of ...']\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m This is the official government website and the data is consistent with my previous searches. I can now confidently answer the question.\n",
            "Final Answer: The GDP of India in 2023 was estimated to be around ₹142.33 lakh crore or approximately US$ 3.5 trillion.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'What was the GDP of India in 2023?',\n",
              " 'output': 'The GDP of India in 2023 was estimated to be around ₹142.33 lakh crore or approximately US$ 3.5 trillion.'}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from langchain.agents import AgentType, initialize_agent, load_tools\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0)\n",
        "\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"serpapi\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "# Let's test it out!\n",
        "agent.invoke(\"What was the GDP of India in 2023?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09cd3a12",
      "metadata": {
        "id": "09cd3a12"
      },
      "source": [
        "#### Wikipedia and llm-math tool"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  wikipedia"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FVcoTf8fhGh",
        "outputId": "37a11528-30b9-4615-f8db-bb1e016dc360"
      },
      "id": "_FVcoTf8fhGh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14d06ce6",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 502
        },
        "id": "14d06ce6",
        "outputId": "729703fa-9608-485c-cbe6-d3309ab12824"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's birthdate and age.\n",
            "Action: Wikipedia\n",
            "Action Input: Elon Musk\u001b[0m\n",
            "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's birthdate and age.\n",
            "Action: Wikipedia\n",
            "Action Input: Elon Musk\u001b[0m\n",
            "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use Wikipedia to find information about Elon Musk's birthdate and age.\n",
            "Action: Wikipedia\n",
            "Action Input: Elon Musk\u001b[0m\n",
            "Observation: Wikipedia is not a valid tool, try one of [wikipedia, Calculator].\n",
            "Thought:\u001b[32;1m\u001b[1;3m I should use Calculator to calculate Elon Musk's age in 2024.\n",
            "Action: Calculator\n",
            "Action Input: 2024 - 1971\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 53\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: Elon Musk was born on June 28, 1971 and will be 53 years old in 2024.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Elon Musk was born on June 28, 1971 and will be 53 years old in 2024.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# install this package: pip install wikipedia\n",
        "\n",
        "# The tools we'll give the Agent access to. Note that the 'llm-math' tool uses an LLM, so we need to pass that in.\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "# Finally, let's initialize an agent with the tools, the language model, and the type of agent we want to use.\n",
        "agent = initialize_agent(\n",
        "    tools,\n",
        "    llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Let's test it out!\n",
        "agent.run(\"When was Elon musk born? What is his age right now in 2024?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6be7ee7",
      "metadata": {
        "id": "b6be7ee7"
      },
      "source": [
        "## Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2acab5d0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2acab5d0",
        "outputId": "954860b8-14f4-4bdf-9f63-b1fc880b6804"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"El Sabor de México\" (The Flavor of Mexico)\n"
          ]
        }
      ],
      "source": [
        "chain = LLMChain(llm=llm,prompt=prompt_template_name)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bc200f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bc200f9",
        "outputId": "83289404-5862-49b8-e675-93ed0d65bc04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Spice Palace\"\n"
          ]
        }
      ],
      "source": [
        "name = chain.run(\"Indian\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229a6888",
      "metadata": {
        "id": "229a6888"
      },
      "outputs": [],
      "source": [
        "chain.memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f492fb5a",
      "metadata": {
        "scrolled": true,
        "id": "f492fb5a",
        "outputId": "14472118-21a1-42a6-f1e2-27bcfda5789c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NoneType"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "type(chain.memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "871492be",
      "metadata": {
        "id": "871492be"
      },
      "source": [
        "#### ConversationBufferMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53eea298",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53eea298",
        "outputId": "1873937a-59dd-450b-f238-1225630345cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"El Sabor de México\" (The Flavor of Mexico)\n"
          ]
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
        "name = chain.run(\"Mexican\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0de5d50b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0de5d50b",
        "outputId": "9b32b457-94e2-4026-9db2-53f5dc53f597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\"Al-Jannah Bistro\"\n"
          ]
        }
      ],
      "source": [
        "name = chain.run(\"Arabic\")\n",
        "print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cc88888",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cc88888",
        "outputId": "cf48c49c-848c-4e9e-83cb-bee0cef80e29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Mexican\n",
            "AI: \n",
            "\n",
            "\"El Sabor de México\" (The Flavor of Mexico)\n",
            "Human: Arabic\n",
            "AI: \n",
            "\n",
            "\"Al-Jannah Bistro\"\n"
          ]
        }
      ],
      "source": [
        "print(chain.memory.buffer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template_item1 = PromptTemplate(\n",
        "    input_variables=[],\n",
        "    template=\"Suggest some different name\"\n",
        ")\n",
        "chain = LLMChain(llm=llm, prompt=prompt_template_name, memory=memory)\n",
        "name1 = chain.invoke(\"\")\n",
        "print(name1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIOzoaPIn4oE",
        "outputId": "e564c6c6-e485-4465-deea-0160d3a08a7b"
      },
      "id": "sIOzoaPIn4oE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'cuisine': '', 'history': 'Human: Mexican\\nAI: \\n\\n\"El Sabor de México\" (The Flavor of Mexico)\\nHuman: Arabic\\nAI: \\n\\n\"Al-Jannah Bistro\"', 'text': '\\n\\n\"Palate Perfection\"'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.memory.buffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTZBys_Jo4aW",
        "outputId": "373f1cbe-ae31-4a06-f778-cd0ddf26edca"
      },
      "id": "pTZBys_Jo4aW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Mexican\n",
            "AI: \n",
            "\n",
            "\"El Sabor de México\" (The Flavor of Mexico)\n",
            "Human: Arabic\n",
            "AI: \n",
            "\n",
            "\"Al-Jannah Bistro\"\n",
            "Human: \n",
            "AI: \n",
            "\n",
            "\"Palate Perfection\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0a88b5b",
      "metadata": {
        "id": "a0a88b5b"
      },
      "source": [
        "#### ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "687ddd2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "687ddd2f",
        "outputId": "52a054eb-20ea-4959-ffdb-8ed972a8a9aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "{history}\n",
            "Human: {input}\n",
            "AI:\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains import ConversationChain\n",
        "\n",
        "convo = ConversationChain(llm=OpenAI(temperature=0.7))\n",
        "print(convo.prompt.template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47ad5062",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "47ad5062",
        "outputId": "4fcd71bd-f3a9-49c1-a934-502cd5b2d464"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The first cricket world cup was held in 1975 and was won by the West Indies team.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "convo.run(\"Who won the first cricket world cup?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03c80b54",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "03c80b54",
        "outputId": "db3631ad-88db-487d-cdf3-a822bee73b4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 5+5 is equal to 10.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "convo.run(\"How much is 5+5?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07342f88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "07342f88",
        "outputId": "9020a552-832d-433e-d7f2-643c03f0ee49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The captain of the West Indies team during the first cricket world cup was Clive Lloyd.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "convo.run(\"Who was the captain ofthe winning team?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e459d07",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e459d07",
        "outputId": "b9d12772-d20d-4d76-cca0-7259e8480b6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Human: Who won the first cricket world cup?\n",
            "AI:  The first cricket world cup was held in 1975 and was won by the West Indies team.\n",
            "Human: How much is 5+5?\n",
            "AI:  5+5 is equal to 10.\n",
            "Human: Who was the captain ofthe winning team?\n",
            "AI:  The captain of the West Indies team during the first cricket world cup was Clive Lloyd.\n"
          ]
        }
      ],
      "source": [
        "print(convo.memory.buffer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "feaa3abd",
      "metadata": {
        "id": "feaa3abd"
      },
      "source": [
        "#### ConversationBufferWindowMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "460eb33c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "460eb33c",
        "outputId": "54be943e-aa7a-4923-d76b-597f5652af9b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Who won the first cricket world cup?',\n",
              " 'history': '',\n",
              " 'response': ' The first cricket world cup was held in 1975 and was won by West Indies. The tournament was organized by the International Cricket Council and was held in England. The final match was between West Indies and Australia, with West Indies winning by 17 runs. The winning team was led by Clive Lloyd and included notable players such as Viv Richards, Gordon Greenidge, and Andy Roberts. It was a historic moment for West Indies cricket and marked the beginning of their dominance in international cricket.'}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from langchain.memory import ConversationBufferWindowMemory\n",
        "\n",
        "memory = ConversationBufferWindowMemory(k=1)\n",
        "\n",
        "convo = ConversationChain(\n",
        "    llm=OpenAI(temperature=0.7),\n",
        "    memory=memory\n",
        ")\n",
        "convo.invoke(\"Who won the first cricket world cup?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d395beaf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d395beaf",
        "outputId": "1015960b-3300-4418-a885-041565d8c66c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'How much is 5+5?',\n",
              " 'history': 'Human: Who won the first cricket world cup?\\nAI:  The first cricket world cup was held in 1975 and was won by West Indies. The tournament was organized by the International Cricket Council and was held in England. The final match was between West Indies and Australia, with West Indies winning by 17 runs. The winning team was led by Clive Lloyd and included notable players such as Viv Richards, Gordon Greenidge, and Andy Roberts. It was a historic moment for West Indies cricket and marked the beginning of their dominance in international cricket.',\n",
              " 'response': '  The sum of 5+5 is 10. Is there anything else you would like to know?'}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "convo.invoke(\"How much is 5+5?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93b24745",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93b24745",
        "outputId": "e075210c-05af-4e0f-8b41-2ccfef6bffec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input': 'Who was the captain of the winning team?',\n",
              " 'history': 'Human: How much is 5+5?\\nAI:   The sum of 5+5 is 10. Is there anything else you would like to know?',\n",
              " 'response': ' I do not have enough context to accurately answer that question. Can you provide me with more information?'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "convo.invoke(\"Who was the captain of the winning team?\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}